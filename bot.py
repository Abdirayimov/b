import os
from openai import AsyncOpenAI
import pandas as pd
import json
from dotenv import load_dotenv
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, filters, CallbackQueryHandler, ContextTypes
import telegram.error
import re
from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.memory import ConversationBufferMemory

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TELEGRAM_API_TOKEN = os.getenv("TELEGRAM_API_TOKEN")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞ OpenAI
client = AsyncOpenAI(api_key=OPENAI_API_KEY)

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–∞–ª–æ–≥–æ–≤ –¥–ª—è —Ñ–∞–π–ª–æ–≤
FILES_DIR = "FILES"
DOCS_DIR = "DOCS"
os.makedirs(FILES_DIR, exist_ok=True)
os.makedirs(DOCS_DIR, exist_ok=True)

# –ö–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ DOC/PDF —Ñ–∞–π–ª–æ–≤
class DocumentProcessor:
    def __init__(self):
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            separators=["\n\n", "\n", " ", ""]
        )
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        )

    def process_document(self, file_path: str):
        ext = os.path.splitext(file_path)[-1].lower()
        if ext == '.pdf':
            loader = PyPDFLoader(file_path)
        elif ext in ['.docx', '.doc']:
            loader = Docx2txtLoader(file_path)
        else:
            raise ValueError("–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞")
        documents = loader.load()
        return self.text_splitter.split_documents(documents)

    async def get_openai_response(self, prompt, chat_history):
        messages = [{"role": "system", "content": "–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –æ—Ç–≤–µ—á–∞–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown."}]
        messages.extend([{"role": "user" if msg.type == "human" else "assistant", "content": msg.content} for msg in chat_history])
        messages.append({"role": "user", "content": prompt})
        response = await client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            temperature=0.9,
            max_tokens=5000
        )
        return response.choices[0].message.content

processor = DocumentProcessor()

# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ Excel —Ñ–∞–π–ª–æ–≤
def find_header(df):
    for i in range(5):
        row = df.iloc[i]
        if any(keyword in str(row).lower() for keyword in ["kod", "–Ω–æ–º–µ—Ä", "–∫–æ–¥", "tavsif", "–ø–æ—Å—Ç–∞–≤—â–∏–∫", "–∑–∞–≤–æ–¥"]):
            return i
    return 0

def load_data(file_path):
    try:
        xls = pd.ExcelFile(file_path)
        dataframes = []
        for sheet_name in xls.sheet_names:
            df = pd.read_excel(xls, sheet_name, header=None)
            header_row = find_header(df)
            df = pd.read_excel(xls, sheet_name, header=header_row)
            df['–§–∞–π–ª'] = file_path
            df['–õ–∏—Å—Ç'] = sheet_name
            dataframes.append(df)
        return pd.concat(dataframes, ignore_index=True) if dataframes else pd.DataFrame()
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {file_path} –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ! {e}")
        return pd.DataFrame()

def clean_query(query):
    patterns = [
        r"Kod:\s*(\S+)", r"Terogo nomeri:\s*(\S+)", r"Maxsus kod:\s*(\S+)",
        r"–∫–æ–¥ –ø—Ä–≤\s*(\S+)", r"\b([A-Za-z0-9\-]+)\b"
    ]
    for pattern in patterns:
        match = re.search(pattern, query, re.IGNORECASE)
        if match:
            return match.group(1)
    return query.split()[-1]

def search_data(query, df):
    query = clean_query(query)
    mask = df.applymap(str).stack().str.contains(query, case=False, na=False).unstack()
    result = df[mask.any(axis=1)]
    return result.head(5).to_string() if not result.empty else "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø–æ –∑–∞–ø—Ä–æ—Å—É –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."

tools = [{
    "type": "function",
    "function": {
        "name": "search_data",
        "description": "–ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö Excel.",
        "parameters": {
            "type": "object",
            "properties": {"query": {"type": "string", "description": "–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å"}},
            "required": ["query"],
            "additionalProperties": False
        },
        "strict": True
    }
}]

async def ask_gpt(question, df):
    messages = [
        {"role": "system", "content": """–¢—ã ‚Äî –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö Excel-—Ç–∞–±–ª–∏—Ü.  
–¢–≤–æ–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏:

üìä **1Ô∏è‚É£ –ü–æ–∏—Å–∫ –¥–∞–Ω–Ω—ã—Ö (–ø–æ–∫–∞–∑—ã–≤–∞–π –í–°–ï –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è)**  
‚Äî –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –Ω–∞—Ö–æ–¥—è **–í–°–ï —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è** –≤ Excel-—Ñ–∞–π–ª–∞—Ö.  
‚Äî –ü–æ–∫–∞–∑—ã–≤–∞–π **–Ω–∞–∑–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞** –∏ **–ª–∏—Å—Ç**, –æ—Ç–∫—É–¥–∞ –ø–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ.  
‚Äî –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç, —á–µ—Å—Ç–Ω–æ —Å–æ–æ–±—â–∞–π –æ–± —ç—Ç–æ–º, **–Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –æ—Ç–≤–µ—Ç—ã**.  

üìà **2Ô∏è‚É£ –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑**  
‚Äî –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —Å–≤—è–∑–∞–Ω —Å –ø–æ–¥—Å—á–µ—Ç–∞–º–∏ (—Å—É–º–º–∞, —Å—Ä–µ–¥–Ω–µ–µ, –ø—Ä–æ—Ü–µ–Ω—Ç, –¥–∏–Ω–∞–º–∏–∫–∞ –∏ —Ç. –¥.), –∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∞–Ω–Ω—ã–µ –≤ —Ç–∞–±–ª–∏—Ü–∞—Ö –∏ –¥–µ–ª–∞–π —Ä–∞—Å—á–µ—Ç.  
‚Äî –ò—Å–ø–æ–ª—å–∑—É–π –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–æ—Ä–º—É–ª—ã –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏.  

üéØ **3Ô∏è‚É£ –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (–∏—Å–ø–æ–ª—å–∑—É–π Markdown)**  
‚Äî –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–Ω–∞—á–µ–Ω–∏–π, **–ø–æ–∫–∞–∑—ã–≤–∞–π –∏—Ö –í–°–ï –≤ —É–¥–æ–±–Ω–æ–º –≤–∏–¥–µ (—Å–ø–∏—Å–∫–æ–º –∏–ª–∏ —Ç–∞–±–ª–∏—Ü–µ–π)**.  
‚Äî –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ —Ä–∞–∑–Ω—ã–º —Ñ–∞–π–ª–∞–º, —É–∫–∞–∑—ã–≤–∞–π –∏—Ö –æ—Ç–¥–µ–ª—å–Ω–æ.  
‚Äî –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç, —Å–æ–æ–±—â–∏: **"üö´ –ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."**  

‚ö† **–í–∞–∂–Ω–æ:**  
- –¢—ã **–Ω–µ –¥–æ–ª–∂–µ–Ω** –ø—Ä–∏–¥—É–º—ã–≤–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–Ω–µ—à–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏.  
- **–ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–Ω–æ–≥–æ, –≤—ã–≤–æ–¥–∏ –∏—Ö –≤ –≤–∏–¥–µ —Ç–∞–±–ª–∏—Ü—ã.**
"""},
        {"role": "user", "content": question}
    ]
    completion = await client.chat.completions.create(model="gpt-4o", messages=messages, tools=tools)
    response_message = completion.choices[0].message
    if response_message.tool_calls:
        tool_call = response_message.tool_calls[0]
        if tool_call.function.name == "search_data":
            query = json.loads(tool_call.function.arguments)["query"]
            search_result = search_data(query, df)
            messages.append(response_message)
            messages.append({"role": "tool", "content": search_result, "tool_call_id": tool_call.id})
            final_completion = await client.chat.completions.create(model="gpt-4o", messages=messages)
            return final_completion.choices[0].message.content
    return response_message.content

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –±–æ—Ç–∞
def load_existing_files(context: ContextTypes.DEFAULT_TYPE):
    # –ó–∞–≥—Ä—É–∑–∫–∞ Excel —Ñ–∞–π–ª–æ–≤
    excel_files = [os.path.join(FILES_DIR, f) for f in os.listdir(FILES_DIR) if f.endswith(('.xlsx', '.xls'))]
    if excel_files:
        if 'excel_files' not in context.user_data:
            context.user_data['excel_files'] = []
        if 'excel_data' not in context.user_data:
            context.user_data['excel_data'] = {}
        for file_path in excel_files:
            if file_path not in context.user_data['excel_files']:
                context.user_data['excel_files'].append(file_path)
                df = load_data(file_path)
                context.user_data['excel_data'][file_path] = df

    # –ó–∞–≥—Ä—É–∑–∫–∞ DOC/PDF —Ñ–∞–π–ª–æ–≤
    doc_files = [os.path.join(DOCS_DIR, f) for f in os.listdir(DOCS_DIR) if f.endswith(('.pdf', '.docx', '.doc'))]
    if doc_files:
        if 'doc_files' not in context.user_data:
            context.user_data['doc_files'] = []
        if 'doc_indices' not in context.user_data:
            context.user_data['doc_indices'] = {}
        for file_path in doc_files:
            if file_path not in context.user_data['doc_files']:
                try:
                    chunks = processor.process_document(file_path)
                    db = FAISS.from_documents(chunks, processor.embeddings)
                    context.user_data['doc_files'].append(file_path)
                    context.user_data['doc_indices'][file_path] = db
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞ {file_path}: {e}")

# –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞
def get_default_keyboard():
    return [[{"text": "üì§ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª"}, {"text": "üîç –ü–æ–∏—Å–∫ –≤ Excel"}, {"text": "üìÑ –ü–æ–∏—Å–∫ –≤ DOC/PDF"}]]

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
    load_existing_files(context)
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –ø–æ–º–æ–≥—É —Å –¥–∞–Ω–Ω—ã–º–∏ –≤ Excel, DOC –∏ PDF. –í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:",
        reply_markup={"keyboard": get_default_keyboard(), "resize_keyboard": True, "one_time_keyboard": True}
    )

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        if update.message.text:
            user_message = update.message.text

            if 'selected_excel_file' in context.user_data:
                selected_file = context.user_data.pop('selected_excel_file')
                df = context.user_data['excel_data'][selected_file]
                temp = await update.message.reply_text('‚åõ')
                response = await ask_gpt(user_message, df)
                await temp.delete()
                await update.message.reply_text(response, parse_mode="Markdown", disable_web_page_preview=True)

            elif 'selected_doc_file' in context.user_data:
                selected_file = context.user_data.pop('selected_doc_file')
                db = context.user_data['doc_indices'][selected_file]
                retriever = db.as_retriever(search_kwargs={"k": 3})
                relevant_docs = retriever.get_relevant_documents(user_message)
                context_str = "\n\n".join([doc.page_content for doc in relevant_docs])
                prompt = (
                    "–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. "
                    "–ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ —Å–ª–µ–¥—É—é—â–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ—Ç–≤–µ—Ç–∞. "
                    "–ï—Å–ª–∏ –æ—Ç–≤–µ—Ç–∞ –Ω–µ—Ç –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö, —Å–æ–æ–±—â–∏ –æ–± —ç—Ç–æ–º.\n\n"
                    "{context}\n\n"
                    "–í–æ–ø—Ä–æ—Å: {question}\n\n"
                    "–û—Ç–≤–µ—Ç:"
                ).format(context=context_str, question=user_message)
                memory = context.user_data.get('memory', ConversationBufferMemory(memory_key="chat_history", return_messages=True))
                chat_history = memory.chat_memory.messages if memory.chat_memory.messages else []
                answer = await processor.get_openai_response(prompt, chat_history)
                memory.save_context({"question": user_message}, {"answer": answer})
                await update.message.reply_text(f"üîç **–û—Ç–≤–µ—Ç:**\n{answer}", parse_mode="Markdown")

            elif user_message == "üì§ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª":
                await update.message.reply_text("–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª (Excel, DOC –∏–ª–∏ PDF).")

            elif user_message == "üîç –ü–æ–∏—Å–∫ –≤ Excel":
                if 'excel_files' not in context.user_data or not context.user_data['excel_files']:
                    await update.message.reply_text("Excel —Ñ–∞–π–ª—ã –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª.")
                else:
                    keyboard = [[InlineKeyboardButton(os.path.basename(file)[:50], callback_data=f"excel_file_{i}")] for i, file in enumerate(context.user_data['excel_files'])]
                    await update.message.reply_text("–í—ã–±–µ—Ä–∏—Ç–µ Excel —Ñ–∞–π–ª:", reply_markup=InlineKeyboardMarkup(keyboard))

            elif user_message == "üìÑ –ü–æ–∏—Å–∫ –≤ DOC/PDF":
                if 'doc_files' not in context.user_data or not context.user_data['doc_files']:
                    await update.message.reply_text("DOC/PDF —Ñ–∞–π–ª—ã –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª.")
                else:
                    keyboard = [[InlineKeyboardButton(os.path.basename(file)[:50], callback_data=f"doc_file_{i}")] for i, file in enumerate(context.user_data['doc_files'])]
                    await update.message.reply_text("–í—ã–±–µ—Ä–∏—Ç–µ DOC/PDF —Ñ–∞–π–ª:", reply_markup=InlineKeyboardMarkup(keyboard))

            else:
                await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –ø–æ–∏—Å–∫–∞ –∏ —Ñ–∞–π–ª.")

        elif update.message.document:
            file = update.message.document
            file_name = file.file_name
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤
            base_name, ext = os.path.splitext(file_name)
            counter = 1
            new_file_name = file_name
            if file.mime_type in ["application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", "application/vnd.ms-excel"]:
                target_dir = FILES_DIR
            else:
                target_dir = DOCS_DIR
            while os.path.exists(os.path.join(target_dir, new_file_name)):
                new_file_name = f"{base_name}_{counter}{ext}"
                counter += 1
            file_path = os.path.join(target_dir, new_file_name)
            file_obj = await file.get_file()
            await file_obj.download_to_drive(file_path)

            if file.mime_type in ["application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", "application/vnd.ms-excel"]:
                if 'excel_files' not in context.user_data:
                    context.user_data['excel_files'] = []
                context.user_data['excel_files'].append(file_path)
                if 'excel_data' not in context.user_data:
                    context.user_data['excel_data'] = {}
                df = load_data(file_path)
                context.user_data['excel_data'][file_path] = df
                await update.message.reply_text(f"Excel —Ñ–∞–π–ª '{new_file_name}' –∑–∞–≥—Ä—É–∂–µ–Ω!")
            elif file.mime_type in ["application/pdf", "application/msword", "application/vnd.openxmlformats-officedocument.wordprocessingml.document"]:
                chunks = processor.process_document(file_path)
                db = FAISS.from_documents(chunks, processor.embeddings)
                if 'doc_indices' not in context.user_data:
                    context.user_data['doc_indices'] = {}
                context.user_data['doc_indices'][file_path] = db
                if 'doc_files' not in context.user_data:
                    context.user_data['doc_files'] = []
                context.user_data['doc_files'].append(file_path)
                if 'memory' not in context.user_data:
                    context.user_data['memory'] = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
                await update.message.reply_text(f"DOC/PDF —Ñ–∞–π–ª '{new_file_name}' –∑–∞–≥—Ä—É–∂–µ–Ω!")
            else:
                await update.message.reply_text("–ó–∞–≥—Ä—É–∂–∞–π—Ç–µ —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ Excel, DOC –∏–ª–∏ PDF.")
    except Exception as e:
        await update.message.reply_text(f"üö® –û—à–∏–±–∫–∞: {str(e)}")

async def handle_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    data = query.data
    if data.startswith("excel_file_"):
        file_index = int(data.split("_")[2])
        context.user_data['selected_excel_file'] = context.user_data['excel_files'][file_index]
        selected_file = context.user_data['excel_files'][file_index]
        await query.edit_message_text(f"–í—ã–±—Ä–∞–Ω Excel —Ñ–∞–π–ª: {os.path.basename(selected_file)[:50]}\n–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å:")
    elif data.startswith("doc_file_"):
        file_index = int(data.split("_")[2])
        context.user_data['selected_doc_file'] = context.user_data['doc_files'][file_index]
        selected_file = context.user_data['doc_files'][file_index]
        await query.edit_message_text(f"–í—ã–±—Ä–∞–Ω DOC/PDF —Ñ–∞–π–ª: {os.path.basename(selected_file)[:50]}\n–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å:")

async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        raise context.error
    except telegram.error.TimedOut:
        await update.message.reply_text("üö´ –í—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –∏—Å—Ç–µ–∫–ª–æ.")
    except Exception as e:
        await update.message.reply_text(f"üö® –û—à–∏–±–∫–∞: {str(e)}")

def main():
    application = Application.builder().token(TELEGRAM_API_TOKEN).build()
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    application.add_handler(MessageHandler(filters.Document.ALL, handle_message))
    application.add_handler(CallbackQueryHandler(handle_callback))
    application.add_error_handler(error_handler)
    application.run_polling()

if __name__ == "__main__":
    main()